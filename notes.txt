
// iris-script recapitulates sylvia-lang, which recapitulates entoli

// syntactically, the final language should be primarily word-based with the minimum punctuation necessary to ensure unambiguous parsing (for discussion purposes, assume a word is any single word, or multiple words separated by underscores, or operator symbol)

// “everything is a command”; there is no distinction between a “variable” and a command with zero arguments. Conceptually, `set foo to 3` is storing the value `3` in the environment's 'foo' slot as if it was simple closure: { ()->Value in return value } (where 'value' is 3). Thus `foo` will always operate as a command; similar to Ruby, there is no distinction between `foo` (name only) or `foo {}` (name + empty arguments record), as there is in Swift/Python/JavaScript/etc.

// all commands behave as right-associative prefix 'operators'; where the right operand may be omitted (in which case it is null). For practical purposes, the operand when given is always treated as a record of zero or more fields, where each field has a value and is optionally labeled. (A record is effectively a tuple/struct hybrid.)

// Q. to what extent could optimization be achieved by eval-ing script against meta-libraries? (i.e. libraries that define the same set of handler interfaces as standard libraries, but whose handlers perform transformations on the initial AST in order to yield a more efficient equivalent)

// Q. what about dead code detection? (e.g. given the script `1, 2, 3.`, `1` and `2` [being side-effectless] are no-ops, while `3` is only relevant if the evaluator is connected to an output console); flagging 'useless' or 'suspect' code may be most useful in parenthesized groups, e.g. `(1,2+3)` will discard the 1 and return 5, but `(foo,2+3)` will return 5 while also performing a potentially effectful `foo` command; being parenthesized, that expr could be buried deep in a much larger expr (while the same effect can be achieved if a `foo` handler is defined that returns its input parameter as output while also performing its side-effect, that requires an explicit definition of `foo` whereas a parenthesized expr sequence works with any existing handler)

// TO DO: how would lexer adapter for multiline strings/annotations work? (upon detecting opening quote, it would return a lexer (or lexer adapter?) that knows how to find the end of that quote [Q. what token would it return in meantime?]) challenge is how to carry that reader forward from end of one line to process next, and finally swap out the quote reader for the standard token reader when done (TBH, it may not be worth the effort when parsing for editing; while slower, having everything tokenized regardless of whether it's code or quoted text gives the auto3cs lots more data to analyze, particularly when best-guessing where missing quotes/closing braces should appear)

// technically `app "TextEdit"` would be `@com.apple.TextEdit` (or however we mount 'application' resources in the superglobal namespace; we might need an extra suffix, e.g. '.file'/'.app'/'.web', or coercion, e.g. `@com.example.foo as file/app/webservice`, to specify the exact service; there's also the question of how to map different namespaces onto the same superglobal root, e.g. UTI vs FS vs WWW; though this is less of an issue if we crosscut resource location with content type negotiation)
